{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec7eadee-387a-4c44-83c5-10b38fb81a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/albertl_uri_edu/fluxtoflow/nldas\n",
      "\n",
      "2617\n"
     ]
    }
   ],
   "source": [
    "#grabs all files in folder with particular file type\n",
    "\n",
    "import glob\n",
    "import os\n",
    "print(os.getcwd() + \"\\n\")\n",
    "\n",
    "dbc = 'ms' #drainage basin code, others are co, ct, ms\n",
    "x = glob.glob(f'clipped__{dbc}/*.nc')\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0718e157-a159-44f7-8798-22ea8172e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26ae24ec-82df-422f-85ca-29fb89f648b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.402225\n",
      "(2617,)\n",
      "y mean (mb): 0.40222499999999994 max: 0.402225 min: 0.402225 y sum: 1052.622825 \n"
     ]
    }
   ],
   "source": [
    "## all file size stuff, showing you what numpy can do.\n",
    "\n",
    "y = np.asarray([os.path.getsize(i)*1e-6 for i in x]) #megabytes found using list comprehension\n",
    "print(y[0]) # prints first file's size\n",
    "print(y.shape) # shape of file list\n",
    "\n",
    "print(f'y mean (mb): {np.mean(y)} '\n",
    "      f'max: {np.max(y)} '\n",
    "      f'min: {np.min(y)} '\n",
    "      f'y sum: {np.sum(y)} '\n",
    "     )\n",
    "#strange that the numbers cut off differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc5a667e-5994-48ba-9ca1-e2e49049beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# we're not using grib files, so disregard the warning here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f7534d6-4310-4e9a-95dc-8f99584d78a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-21T13:20:40.962765-04:00\n",
      "br\ttorch.Size([2617, 2, 16, 15])\t95.26270651817322 seconds\n",
      "2022-06-21T13:22:16.227419-04:00\n",
      "2022-06-21T13:22:16.309504-04:00\n",
      "co\ttorch.Size([2617, 2, 100, 91])\t275.13034653663635 seconds\n",
      "2022-06-21T13:26:51.441420-04:00\n",
      "2022-06-21T13:26:53.489200-04:00\n",
      "ct\ttorch.Size([2617, 2, 32, 16])\t97.14105033874512 seconds\n",
      "2022-06-21T13:28:30.632309-04:00\n",
      "2022-06-21T13:28:30.774961-04:00\n",
      "ms\ttorch.Size([2617, 2, 167, 288])\t948.301483631134 seconds\n",
      "2022-06-21T13:44:19.078013-04:00\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import arrow\n",
    "import time\n",
    "\n",
    "def nc2torch(i):\n",
    "    return torch.from_numpy(np.asarray(i)).unsqueeze(0)\n",
    "\n",
    "\n",
    "def combine(dbc):\n",
    "    print(arrow.now('US/Eastern'))\n",
    "    t0 = time.time()\n",
    "    x = glob.glob(f'clipped__{dbc}/*.nc')\n",
    "    xx = xr.open_dataset(x[0]) # just as a reference for shape in dset...\n",
    "    dset = torch.empty([0,2,xx.Qs_summed.shape[0],xx.Qs_summed.shape[1]]) # instantiates empty torch tensor.\n",
    "\n",
    "    #grabs every daily file in folder, opens it, grabs surface and subsurface flow, and combines them into a pytorch tensor for the neural network.\n",
    "    for i in sorted(x):\n",
    "        j = xr.open_dataset(i)\n",
    "        z0 = nc2torch(j.Qs_summed) # calling nc2torch function, which is taking the numpy matrix and turning it into tensor.\n",
    "        z1 = nc2torch(j.Qsb_summed)\n",
    "        z2 = torch.cat((z0,z1),axis=0).unsqueeze(0)\n",
    "        dset = torch.cat((dset,z2),axis=0)\n",
    "    t1 = time.time()\n",
    "    print(f'{dbc}\\t{dset.shape}\\t{t1-t0} seconds')\n",
    "    print(arrow.now('US/Eastern'))\n",
    "    torch.save(dset,f'nldas_{dbc}.pt')\n",
    "    return _\n",
    "\n",
    "x = ['br','co','ct','ms']\n",
    "for i in x:\n",
    "    combine(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12062d5e-55f6-4bed-884c-c456e994bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dset,'nldas_ms.pt') # i like to have this in a different field so i can execute it as i please."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-sm)",
   "language": "python",
   "name": "conda-env-.conda-sm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
